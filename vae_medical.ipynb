{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FLvJrfs8kYYF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Variational Autoencoder\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3*64*64, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, latent_dim*2))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 3*64*64),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_hat = self.decoder(z)\n",
        "        return x_hat, mu, logvar\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 3*64*64), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "fBh6GbFlD6Bg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "dataset = ImageFolder('/content/drive/MyDrive/Colab Notebooks/Mini Project/', transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "6JAXQR-3D5-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(10):  # Tune this\n",
        "    for batch, _ in loader:\n",
        "        batch = batch.to(device)\n",
        "        recon_batch, mu, logvar = vae(batch)\n",
        "        loss = vae_loss(recon_batch, batch, mu, logvar)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}], Loss: {loss.item():.2f}\")\n",
        "    save_image(batch[0], f\"/content/drive/MyDrive/Colab Notebooks/Mini Project/original_epoch{epoch+1}.png\")\n",
        "    save_image(recon_batch[0].view(3, 64, 64), f\"/content/drive/MyDrive/Colab Notebooks/Mini Project/recon_epoch{epoch+1}.png\")\n",
        "    torch.save(vae.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/Mini Project/vae_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1r9EzzKD55a",
        "outputId": "1756e2a2-28e2-483d-8424-54f6919ac9f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Loss: 171992.81\n",
            "Epoch [2], Loss: 186095.23\n",
            "Epoch [3], Loss: 173264.36\n",
            "Epoch [4], Loss: 172199.09\n",
            "Epoch [5], Loss: 170922.94\n",
            "Epoch [6], Loss: 170683.64\n",
            "Epoch [7], Loss: 170690.97\n",
            "Epoch [8], Loss: 170620.61\n",
            "Epoch [9], Loss: 170579.23\n",
            "Epoch [10], Loss: 170551.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1R0XTcwjvaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}